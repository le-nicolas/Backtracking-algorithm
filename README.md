# Backtracking-algorithm
Computers will dominate our technical lives and when compared to Humans they have the advantages. They are far more accurate (and precise),
far more reliable â€”very far ahead (many have error correction built into them), can change programs, also unlearn and then learn the new thing. (in which we humans consume hours and hours of
time and effort). but, only a rapid "computer control" to make them practical.

![Backtracking](https://github.com/le-nicolas/Backtracking-algorithm/assets/112614851/dd740d21-085d-461d-aac9-0228abb58d5c)


Here, I present a nice "computer control" called backtracking algorithm. it help explore different options to find the best solution. In my understanding, its kind of like backpropagation but in a different variation. It systematically explores different possibilities by trying out values for each cell. If it reaches a dead end where it cannot find a valid value for a cell, it backtracks to the previous cell and tries a different value.

what I love about this method is that it is effective for problems with large search spaces where trying every possible combination would be impractical. 



whereas backprop, is to minimize the error between the predicted and actual output.
optimizes the weights of the neural network by minimizing the error function
It propagates the error from the output layer back to the input layer, adjusting weights to reduce the error.
Inputs are passed through the network to get the output.
The error is calculated as the difference between the predicted and actual outputs.
The error is propagated backward through the network, and gradients of the error with respect to each weight are calculated.
Weights are updated using the calculated gradients to minimize the error
![maxresdefault (1)](https://github.com/le-nicolas/Backtracking-algorithm/assets/112614851/4fb93d8b-74b7-4fb3-b621-27c47470c0b0)












TL;DR they are kind of the same, but different approach to a different purpose.
